encoder:
  seed_everything: true
  model:
    class_path: cyber.models.world.autoencoder.VQModel
    init_args:
      ddconfig:
        double_z: False
        z_channels: 18
        resolution: 128
        in_channels: 3
        out_ch: 3
        ch: 128
        ch_mult: [1,1,2,2,4]  # num_down = len(ch_mult)-1
        num_res_blocks: 4
      lossconfig:
        class_path: cyber.models.world.autoencoder.magvit2.modules.losses.vqperceptual.VQLPIPSWithDiscriminator
        init_args:
          disc_conditional: False
          disc_in_channels: 3
          disc_start: 0
          disc_weight: 0.8
          gen_loss_weight: 0.1
          lecam_loss_weight: 0.01
          codebook_weight: 0.1
          commit_weight: 0.25
          codebook_enlarge_ratio: 0
          codebook_enlarge_steps: 2000
      n_embed: 262144
      embed_dim: 18
      learning_rate: 1e-4
      sample_minimization_weight: 1.0
      batch_maximization_weight: 1.0
      scheduler_type: "None"
      use_ema: True
      resume_lr:
      lr_drop_epoch: [250, 300]
      ckpt_path: null # to resume


dynamic:
  class_path: cyber.models.world.dynamic.genie.st_mask_git.STMaskGIT
  init_args:
    num_layers: 32
    num_heads: 8
    d_model: 256
    T: 16
    S: 256
    image_vocab_size: 262144
    use_mup: false
    num_factored_vocabs: 2
    factored_vocab_size: 512
    max_corrupt_rate: 0.2
    non_mlm_ratio: 0.5
    num_prompt_frames: 8
    qkv_bias: false
    proj_bias: true
    attn_drop: 0
    qk_norm: false
    mlp_ratio: 4
    mlp_drop: 0
    mlp_bias: true
